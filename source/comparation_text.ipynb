{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import anthropic\n",
    "from openai import OpenAI\n",
    "\n",
    "import base64\n",
    "import httpx\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from IPython.display import Image,display\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "BLUE = '\\033[94m'\n",
    "END = '\\033[0m' \n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "claude_client = anthropic.Anthropic(api_key=os.environ[\"CLAUDE_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_1(question):\n",
    "    prompt = '''\n",
    "            CONTEXT:\n",
    "            You are a chatbot that answers questions. \n",
    "            Answer do not include disclaimer.\n",
    "            Answer should have a dry tone.\n",
    "            \n",
    "            QUESTION:\n",
    "            Answer to this question: \n",
    "            {question}\n",
    "            \n",
    "            OUTPUT:\n",
    "            Output is JSON object.\n",
    "\n",
    "            [\n",
    "                {{\"result\": \"answer\"}}\n",
    "            ]\n",
    "            \n",
    "            '''\n",
    "    prompt = prompt.format(question=question)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def create_prompt_2(item):\n",
    "    prompt = '''\n",
    "            CONTEXT:\n",
    "            You are a data analyst API capable of item analysis.\n",
    "            Please list the semantic queries that would be used to find the given item {item}.\n",
    "            Answer do not include disclaimer.\n",
    "            Answer do not include the item itself.\n",
    "            Answer should have a dry tone.\n",
    "            \n",
    "            OUTPUT:\n",
    "            Output is JSON object.\n",
    "\n",
    "            [\n",
    "                {{\"result\": [\"semantic queries 1\",\n",
    "                             \"semantic queries 2\",\n",
    "                             ...,\n",
    "                             \"semantic queries n\",\n",
    "                            ]}}\n",
    "            ]\n",
    "            \n",
    "            '''\n",
    "    prompt = prompt.format(item=item)\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def create_prompt_3(text):\n",
    "    prompt = '''\n",
    "            CONTEXT:\n",
    "            For the given short story give me brief summary.\n",
    "\n",
    "            {text}\n",
    "            Just do it, so the T-shirts say. Just pick up the gun, pull the trigger—but maybe aim first, aim at the upper sternum and then pull the trigger, congratulating yourself that at last, in your long, passive life, you have shot somebody dead. \n",
    "            So she did, and thus she became a murderer. She slipped through the night after that and disappeared into the willows to wash off any blood that spattered onto her clothing. \n",
    "            The willows were thickly interlaced, with an overpowering smell, acrid and watery. The stream flowed through and among them. She washed her hands and face, even her elbows, and pushed her way through the restraining arms of willows wherever she could find a gap. The ditches were deep. Sometimes she put a foot down in one and fell, grabbing at willows to drag herself back up again so she could keep running.\n",
    "            How long could she run, and where? Pretty soon the willows ended, by the bank of the creek that was swift, dark, bitter cold and deep. Can't run there. Run down along the shore, scraping under a barbwire fence, not running but walking or stumbling, because there seemed no rhyme or reason for the contour of the ground in the dark. There was faint moonlight, from a half moon; she was afraid she would be seen in it, even though she didn't know if there was anyone to see her. \n",
    "            Had there been another besides the one she shot? He couldn't have been alone; she was sure she had heard them talking—short grunts of laughter, murmurs of discovery. Where was the other? Was it possible he was out looking for her? He'd be scrambling, that's for sure, not knowing the territory, confused and annoyed by the scratching of resistant willow twigs that sprang back and slapped the flesh.\n",
    "            Her shoes were wet and heavy. Every step sucked mud. The sound of it traveled through the quiet night until she couldn't imagine she wouldn't be caught. If he caught her, she was dead. Probably worse than dead. It didn't pay to think a lot about how much worse than dead a thing could be. She needed all her thought to be on escape. In whispers she told herself how she was coming along, kept a running commentary on what a good job she was doing, and gave herself warnings about dangerous footing or sudden patches of open space.\n",
    "            She thought about how she hadn't brought the gun. Maybe not bringing it meant he would have it now. But she couldn't have gotten as far as she had if she'd been saddled with trying to work the rifle barrel through these branches. And there was still one bullet in it, so she might have shot it off, shot her own foot, shot an advertisement of her location into the night sky. But now maybe he had the rifle, and it did have one bullet in it. He would not find any stash of ammunition, because there wasn't one. The two bullets had been all. And if he came after her, he would have more trouble than she would have had traveling through the willows, since he didn't know them and she did.\n",
    "            Or maybe he was a fisherman, in which case he would be perfectly familiar with willows and know how to penetrate them without becoming immovably trapped in the twist and winding of their slippery, springy fingers. Maybe he was a fisherman and a woodsman, and was right now somewhere behind her, close behind her even, holding the rifle high, worming it through the spaces like someone from a movie. When she paused, she thought she could even hear that—an occasional snap where a foot bent a branch and broke it off, an occasional wet splat as from a foot pulling out of a mud ditch.\n",
    "            Then she was in the willows again herself, and the breath was so painful in her pressed lungs there was no room for another. She had to stop. She could and should stop. It would give her a chance to listen and know for sure. She was safe here in this thicket, as safe as a deer, as safe as a fawn curled among the branches while its mother went away. She opened her mouth in a big round O and let the breaths come in, large and noiseless, go out the same way. Not quite noiseless; there was a shaky panting sound she couldn't repress. But it might not be heard over the white noise of the creek straining through the willows.\n",
    "            And now that she wasn't running, she had to think. She had to remember. It made her eyes dilate and water, to remember the horror she'd felt when first she heard them walking across the gravel. Those grunts of laughter, murmurs of discovery, she could hear them clearly now. She could remember the creaks on the stairs from her own feet carrying her up to get the .30-30. She remembered the clucking sound as the lid popped out of the nearly empty cardboard ammo box, the dreadful click as she opened the magazine and slid the two bullets in. Closing the lever—that sound had been covered by a sound from downstairs, a sharp “hello!” Then there was the sound of them clumping from room to room, also a moving flicker from their flashlight. She thought she remembered seeing the one, all of a sudden, appearing at the top of the stairs, oh yes, she’d been pressed against the wall listening to their progress, and they’d been quiet, too, maybe scared themselves. Maybe awed by the size and emptiness of the house that wasn't theirs.\n",
    "            But she never saw the other. She saw the one—first the circle of his flashlight and then the form behind it. She saw the light beam search her bedroom from side to side. She felt it cross her body and rapidly return to it, then aim directly at her face. “We're not alone,” called his voice, sing-song, and she hated the voice. It contained so much of her own fear, like a hideous magnifying mirror, and she knew without waiting another second that he would do her great harm. So she aimed at the part that would be the upper sternum because once she had seen Rick shoot a standing bear that way. When she pulled the trigger, the man made the same sound the bear had made, SHIIUUH, and the flashlight thumped across the floor. There it lay, shining on the place where the bureau leg stood on the carpet. \n",
    "            In the ensuing silence, which was staggering, she had set the gun down, picked up the flashlight, and shone it on the body. It was dead. There was no other word for it, for the way the eyes were up and sideways in a gaze no living eyes could hold. There was the blood, much of it seeping out from under the man—the boy, almost, she remembered now, a big overgrown boy, his life blood seeping onto her carpet, which was, or had been, beautiful and precious to her so that she felt an even greater anger. Anger that she had been forced to kill this kid who'd lived so short a life, anger that her carpet was horrifyingly blood-soaked, anger that she had acted from fear without weighing the choices.\n",
    "            All her hair had been standing on end. That's how it felt, though it couldn't actually have been, because her hair was too long to stand on end. She remembered the surge of electricity that had come rushing through her when the deed was done, how she crouched with her mouth wide open in wonder and thought, I have killed somebody. He is lying here dead and I shot him. It was a feeling of victory beyond anything she had ever experienced—instantaneous certainty that she ruled the world and the heavens. Victory that lasted a minute or less and was replaced by sickening panic. Where was the other intruder? Was he crouching downstairs, not breathing, wondering if he was dreaming, wondering if he would be next? Had he run away?\n",
    "            But she could not go down and find out. \n",
    "            Not only that, she couldn't go down and escape, because maybe he was there, waiting. Yes, probably he was there. She would have to let herself out through the window, with the twisted sheets tied together the way she'd never thought she herself would actually be doing, and she would have to do it so quietly the other wouldn’t hear or see. This she couldn’t do. \n",
    "            But she had tied the sheets and let them out the window, securing the end on the hat hook. Then she had grabbed a little suitcase, crept with it all the way to the other side of the house, and thrown it through another window, shattering the glass. If the other was still there, he would surely go in the direction of the sound, or at least his attention would. Then she tiptoed back, balanced on the edge of her own window, and let herself down the sheets as quietly as she could. When her feet touched the ground, she waited for many minutes, for maybe ten minutes, and never heard whether the other was there or not. She heard nothing. That was when she had made a run for it, across a small slope of meadow to the nearest clump of willows, praying all the way, spurt by spurt, until she reached the main growth where the willow branches enclosed and hid her.\n",
    "            How could she have done this? How could she have done any of it? She had not known, so she thought, how to load the rifle. She had not known how to fire it. She had not known how to descend on a twist of sheets. There had been something working in her that was quite unknown to her conscious knowledge of herself yet apparently fully developed. Developed when, in her sleep? All the nights she had lain sleeping? Was she all that time developing the secret ability to be a killer and an escapee?\n",
    "            As she paused again for breath, and to listen, she began to see it was more important at this point to run to, rather than away. Just running away meant she would have to keep on running, forever. She knew she couldn't do that. The obvious plan was to go to the Seymours for help. The Seymours were the nearest neighbors, three miles down the road. She was sure she had run more than three miles, but she didn't know how many of those miles were in a straight line. She thought, though, that the tiny flicker of light blinking occasionally behind the pines might be from their ranch. And when she came to a sweep of pasture land, she was sure of it. She began to run again because the grazed grass made it so easy, and the hope in her heart was expanding like a sunrise. A few minutes later, she staggered into their driveway, panting and heaving, and banged with her fist on the door. They were certainly home, because there was their pickup, a Dodge Ram.\n",
    "            \"Well, hi there, neighbor,\" said Ida Seymour, in that way she had of saying 'neighbor' that sounded as if she had learned it in a storybook. “Heavens, you look like you might have ran here!”\n",
    "            Ida Seymour had opened the door wide for her, so she walked on into the mudroom feeling half grateful. Only half. She had another feeling, too, but it took a few seconds for her to pin it down: Do the Seymours drive a Dodge Ram? It was a nasty spark that might or might not go out when it hit the ground. She had a very strong impulse to turn around and keep running. Ida Seymour, however, was propelling her on into the kitchen, talking all the while, “You're the second visitor we've had tonight! You wouldn't guess, but we have this fellow who says there's been a killing up the creek, in an abandoned house. Willie told him, what abandoned house? There’s only the one house. Which of course is yours. Right off, we thought about you and hoped you were alright! But anyway, Willie is on the phone to the sheriff this minute. Come on in!”\n",
    "            She came on in. She had to. The man at the kitchen table seemed young too, though older than the other, the dead one. His wheat-grass hair hung down all around from under the edges of his baseball cap, and his plaid flannel shirt was the shirt anyone in this part of the country would wear. He was hunched over, his hands wrapped almost desperately around a cup of black coffee. His face with its haggard blue eyes was at this moment raising toward hers, and in its clammy unhuman whiteness she saw a reflection of how her own face must look; it couldn't look any other way. A look comprised of shock, horror, revulsion, and naked fear.\n",
    "            Willie Seymour stood behind him, the receiver halfway to his ear. He started to lower it, and she saw in his eyes a slow trickle of comprehension. Then that slow trickle seemed to pass from one set of eyes to another, getting less slow by the second, so that she began to fear, as she had feared in the willows. Feared more, because she couldn’t run. She had already run to the end.\n",
    "            Of course she feared. She should have thought of it before. There was a murderer in this room—and everyone present knew who it was.\n",
    "                        \n",
    "            OUTPUT:\n",
    "            Output is JSON object.\n",
    "            Output must be in this form:\n",
    "\n",
    "            [\n",
    "                {{\"summary\": \"story_summary\"}}\n",
    "            ]\n",
    "            \n",
    "            '''\n",
    "    prompt = prompt.format(text=text)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_description(question, num_prompt = 1):\n",
    "    \n",
    "    if num_prompt == 1:\n",
    "        prompt = create_prompt_1(question)\n",
    "    elif num_prompt == 2:\n",
    "        prompt =  create_prompt_2(question)\n",
    "    elif num_prompt == 3:\n",
    "        prompt =  create_prompt_3(question)\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "      model=\"gpt-4-vision-preview\",\n",
    "      messages=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            }\n",
    "            \n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      temperature=0.5,\n",
    "      max_tokens=2000,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def opus_description(question, num_prompt = 1):\n",
    "    \n",
    "    if num_prompt == 1:\n",
    "        prompt = create_prompt_1(question)\n",
    "    elif num_prompt == 2:\n",
    "        prompt =  create_prompt_2(question)\n",
    "    elif num_prompt == 3:\n",
    "        prompt =  create_prompt_3(question)\n",
    "    \n",
    "    response = claude_client.messages.create(\n",
    "                model='claude-3-opus-20240229', \n",
    "                messages=[\n",
    "                  {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                  }\n",
    "                ],\n",
    "                max_tokens=2000,\n",
    "                temperature=0.5,\n",
    "              )\n",
    "    return response\n",
    "\n",
    "\n",
    "def sonnet_description(question, num_prompt = 1):\n",
    "    \n",
    "    if num_prompt == 1:\n",
    "        prompt = create_prompt_1(question)\n",
    "    elif num_prompt == 2:\n",
    "        prompt =  create_prompt_2(question)\n",
    "    elif num_prompt == 3:\n",
    "        prompt =  create_prompt_3(question)\n",
    "    \n",
    "    response = claude_client.messages.create(\n",
    "                model='claude-3-sonnet-20240229', \n",
    "                messages=[\n",
    "                  {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                  }\n",
    "                ],\n",
    "                max_tokens=2000,\n",
    "                temperature=0.5,\n",
    "              )\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "def haiku_description(question, num_prompt = 1):\n",
    "    \n",
    "    if num_prompt == 1:\n",
    "        prompt = create_prompt_1(question)\n",
    "    elif num_prompt == 2:\n",
    "        prompt =  create_prompt_2(question)\n",
    "    elif num_prompt == 3:\n",
    "        prompt =  create_prompt_3(question)\n",
    "    \n",
    "    response = claude_client.messages.create(\n",
    "                model='claude-3-haiku-20240307', \n",
    "                messages=[\n",
    "                  {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                  }\n",
    "                ],\n",
    "                max_tokens=2000,\n",
    "                temperature=0.5,\n",
    "              )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_gpt(total, prompt_tokens, completion_tokens):\n",
    "    return (((total * prompt_tokens)/1000000) * 10) + (((total * completion_tokens)/1000000) * 30)\n",
    "\n",
    "def cost_opus(total, input_token, output_token):\n",
    "  return(((total * input_token)/1000000) * 15) + (((total * output_token)/1000000) * 75)\n",
    "\n",
    "def cost_sonnet(total, input_token, output_token):\n",
    "  return(((total * input_token)/1000000) * 3) + (((total * output_token)/1000000) * 15)\n",
    "\n",
    "def cost_haiku(total, input_token, output_token):\n",
    "  return(((total * input_token)/1000000) * 0.25) + (((total * output_token)/1000000) * 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[94mGPT-4-1106-preview\u001b[0m \n",
      "\n",
      "Time:  2.95 seconds \n",
      "\n",
      "Number of input tokens: 76\n",
      "Number of output tokens: 48 \n",
      "\n",
      "Cost for 100k queries:  $220.0 $\n",
      "Cost per query:  $0.0022 $ \n",
      "\n",
      "[\n",
      "    {\"result\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system.\"}\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mOpus\u001b[0m \n",
      "\n",
      "Time:  7.89 seconds \n",
      "\n",
      "Number of input tokens: 96\n",
      "Number of output tokens: 151 \n",
      "\n",
      "Cost for 100k queries: 1276.5 $\n",
      "Cost per query:  0.012765 $ \n",
      "\n",
      "[\n",
      "    {\n",
      "        \"result\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, and futurist best known for his contributions to the design of the modern alternating current (AC) electricity supply system. Born in 1856, Tesla developed a number of groundbreaking technologies, including the Tesla coil, fluorescent lighting, the induction motor, and early X-ray imaging. He also explored the possibilities of wireless power transmission. Despite his numerous innovations, Tesla struggled financially later in life and died in relative obscurity in 1943. Today, he is widely recognized as one of the most influential and visionary figures in the history of science and technology.\"\n",
      "    }\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mSonnet\u001b[0m \n",
      "\n",
      "Time:  2.5 seconds \n",
      "\n",
      "Number of input tokens: 96\n",
      "Number of output tokens: 110 \n",
      "\n",
      "Cost for 100k queries: 193.8 $\n",
      "Cost per query:  0.001938 $ \n",
      "\n",
      "[{\"result\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist. He is best known for his contributions to the design of the modern alternating current (AC) electricity supply system. Tesla made numerous revolutionary discoveries during the late 19th and early 20th centuries, including the invention of the Tesla coil, which laid the foundation for wireless technologies. He also made significant contributions to the fields of electromagnetism, robotics, and ballistics.\"}]\n",
      "\n",
      "\n",
      "\u001b[94mHaiku\u001b[0m \n",
      "\n",
      "Time:  1.63 seconds \n",
      "\n",
      "Number of input tokens: 96\n",
      "Number of output tokens: 107 \n",
      "\n",
      "Cost for 100k queries: 15.775 $\n",
      "Cost per query:  0.00015775 $ \n",
      "\n",
      "[\n",
      "    {\"result\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, and futurist who is best known for his contributions to the design of the modern alternating current (AC) electricity supply system. He is also known for his work on the rotating magnetic field, the Tesla coil, and the discovery of the rotating magnetic field principle which formed the basis of most AC machinery. Tesla held over 300 patents and was a prolific inventor and visionary.\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "question = 'Who is Nikola Tesla'\n",
    "num_prompt = 1\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'GPT-4-1106-preview' + END, '\\n')\n",
    "st = time.time()\n",
    "result_gpt = gpt_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_gpt.usage.prompt_tokens)\n",
    "print('Number of output tokens:', result_gpt.usage.completion_tokens, '\\n')\n",
    "print('Cost for 100k queries: ', f'${cost_gpt(100000,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $')\n",
    "print('Cost per query: ', f'${cost_gpt(1,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $','\\n')\n",
    "for l in result_gpt.choices[0].message.content.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Opus' + END, '\\n')\n",
    "st = time.time()\n",
    "result_opus = opus_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_opus.usage.input_tokens)\n",
    "print('Number of output tokens:', result_opus.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_opus(100000,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_opus(1,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $','\\n')\n",
    "for l in result_opus.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Sonnet' + END, '\\n')\n",
    "st = time.time()\n",
    "result_sonnet = sonnet_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_sonnet.usage.input_tokens)\n",
    "print('Number of output tokens:', result_sonnet.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_sonnet(100000,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_sonnet(1,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $','\\n')\n",
    "for l in result_sonnet.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Haiku' + END, '\\n')\n",
    "st = time.time()\n",
    "result_haiku = haiku_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_haiku.usage.input_tokens)\n",
    "print('Number of output tokens:', result_haiku.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_haiku(100000,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_haiku(1,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $','\\n')\n",
    "for l in result_haiku.content[0].text.split('\\n'):\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[94mGPT-4-1106-preview\u001b[0m \n",
      "\n",
      "Time:  5.0 seconds \n",
      "\n",
      "Number of input tokens: 108\n",
      "Number of output tokens: 71 \n",
      "\n",
      "Cost for 100k queries:  $321.0 $\n",
      "Cost per query:  $0.00321 $ \n",
      "\n",
      "{\n",
      "    \"result\": [\n",
      "        \"mobile device\",\n",
      "        \"cell phone\",\n",
      "        \"handheld communication device\",\n",
      "        \"portable electronic device\",\n",
      "        \"wireless communication device\",\n",
      "        \"smart mobile phone\",\n",
      "        \"internet-enabled device\",\n",
      "        \"touchscreen device\",\n",
      "        \"Android or iOS device\",\n",
      "        \"personal digital assistant\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "\u001b[94mOpus\u001b[0m \n",
      "\n",
      "Time:  5.44 seconds \n",
      "\n",
      "Number of input tokens: 133\n",
      "Number of output tokens: 105 \n",
      "\n",
      "Cost for 100k queries: 987.0 $\n",
      "Cost per query:  0.00987 $ \n",
      "\n",
      "Here is the JSON object with semantic queries to find the item \"Smartphone\":\n",
      "\n",
      "[\n",
      "    {\"result\": [\n",
      "        \"mobile device with touchscreen and internet connectivity\",\n",
      "        \"handheld computer that can make phone calls and run apps\", \n",
      "        \"cell phone with advanced computing capabilities\",\n",
      "        \"pocket-sized device combining phone, web browser, and other features\",\n",
      "        \"internet-enabled telephone with camera, GPS, and app support\"\n",
      "    ]}\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mSonnet\u001b[0m \n",
      "\n",
      "Time:  3.86 seconds \n",
      "\n",
      "Number of input tokens: 133\n",
      "Number of output tokens: 148 \n",
      "\n",
      "Cost for 100k queries: 261.9 $\n",
      "Cost per query:  0.002619 $ \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"result\": [\n",
      "      \"mobile phone\",\n",
      "      \"cell phone\",\n",
      "      \"handheld device\",\n",
      "      \"portable communication device\",\n",
      "      \"touchscreen device\",\n",
      "      \"iOS device\",\n",
      "      \"Android device\",\n",
      "      \"5G phone\",\n",
      "      \"4G phone\",\n",
      "      \"unlocked phone\",\n",
      "      \"camera phone\",\n",
      "      \"smartphone camera\",\n",
      "      \"phone storage\",\n",
      "      \"phone battery\",\n",
      "      \"phone processor\",\n",
      "      \"phone display\",\n",
      "      \"phone RAM\",\n",
      "      \"phone brand\",\n",
      "      \"phone model\",\n",
      "      \"phone price\"\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mHaiku\u001b[0m \n",
      "\n",
      "Time:  1.78 seconds \n",
      "\n",
      "Number of input tokens: 133\n",
      "Number of output tokens: 89 \n",
      "\n",
      "Cost for 100k queries: 14.45 $\n",
      "Cost per query:  0.0001445 $ \n",
      "\n",
      "[\n",
      "    {\n",
      "        \"result\": [\n",
      "            \"mobile device\",\n",
      "            \"cellular phone\",\n",
      "            \"handheld computing device\",\n",
      "            \"portable communication device\",\n",
      "            \"touchscreen interface\",\n",
      "            \"mobile operating system\",\n",
      "            \"mobile app ecosystem\",\n",
      "            \"wireless connectivity\",\n",
      "            \"multimedia capabilities\",\n",
      "            \"personal digital assistant\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "question = 'Smartphone'\n",
    "num_prompt = 2\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'GPT-4-1106-preview' + END, '\\n')\n",
    "st = time.time()\n",
    "result_gpt = gpt_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_gpt.usage.prompt_tokens)\n",
    "print('Number of output tokens:', result_gpt.usage.completion_tokens, '\\n')\n",
    "print('Cost for 100k queries: ', f'${cost_gpt(100000,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $')\n",
    "print('Cost per query: ', f'${cost_gpt(1,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $','\\n')\n",
    "for l in result_gpt.choices[0].message.content.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Opus' + END, '\\n')\n",
    "st = time.time()\n",
    "result_opus = opus_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_opus.usage.input_tokens)\n",
    "print('Number of output tokens:', result_opus.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_opus(100000,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_opus(1,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $','\\n')\n",
    "for l in result_opus.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Sonnet' + END, '\\n')\n",
    "st = time.time()\n",
    "result_sonnet = sonnet_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_sonnet.usage.input_tokens)\n",
    "print('Number of output tokens:', result_sonnet.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_sonnet(100000,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_sonnet(1,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $','\\n')\n",
    "for l in result_sonnet.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Haiku' + END, '\\n')\n",
    "st = time.time()\n",
    "result_haiku = haiku_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_haiku.usage.input_tokens)\n",
    "print('Number of output tokens:', result_haiku.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_haiku(100000,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_haiku(1,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $','\\n')\n",
    "for l in result_haiku.content[0].text.split('\\n'):\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[94mGPT-4-1106-preview\u001b[0m \n",
      "\n",
      "Time:  7.67 seconds \n",
      "\n",
      "Number of input tokens: 2869\n",
      "Number of output tokens: 99 \n",
      "\n",
      "Cost for 100k queries:  $3166.0 $\n",
      "Cost per query:  $0.03166 $ \n",
      "\n",
      "[\n",
      "    {\"summary\": \"A woman becomes a murderer after shooting an intruder in her home. She flees into the willows to clean herself and escape, but is pursued by another intruder. She runs through the night, unsure of where to go, until she decides to seek help from her neighbors, the Seymours. Upon arrival, she realizes the other intruder is already there, pretending to be a victim, and she is trapped with no way to escape.\"}\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mOpus\u001b[0m \n",
      "\n",
      "Time:  11.0 seconds \n",
      "\n",
      "Number of input tokens: 3035\n",
      "Number of output tokens: 153 \n",
      "\n",
      "Cost for 100k queries: 5700.0 $\n",
      "Cost per query:  0.056999999999999995 $ \n",
      "\n",
      "Here is the summary of the short story in JSON format:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"summary\": \"A woman shoots and kills an intruder in her home. Panicked, she flees into the nearby willows, trying to escape through the difficult terrain while fearing the intruder's accomplice may be pursuing her. Exhausted, she makes her way to the neighboring Seymour ranch for help. However, the accomplice is already there, having told the Seymours about a killing at the woman's house. As the truth dawns on everyone present, the woman realizes she has run out of options and that the others now know she is the murderer.\"\n",
      "    }\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mSonnet\u001b[0m \n",
      "\n",
      "Time:  5.12 seconds \n",
      "\n",
      "Number of input tokens: 3035\n",
      "Number of output tokens: 98 \n",
      "\n",
      "Cost for 100k queries: 1057.5 $\n",
      "Cost per query:  0.010575000000000001 $ \n",
      "\n",
      "[\n",
      "  {\n",
      "    \"summary\": \"A woman shoots and kills an intruder in her home out of fear. She flees through the willows, unsure if there was another intruder. After a harrowing journey, she seeks help from her neighbors, the Seymours. However, when she arrives, she realizes the other intruder is there, and they all recognize her as the murderer.\"\n",
      "  }\n",
      "]\n",
      "\n",
      "\n",
      "\u001b[94mHaiku\u001b[0m \n",
      "\n",
      "Time:  3.21 seconds \n",
      "\n",
      "Number of input tokens: 3035\n",
      "Number of output tokens: 187 \n",
      "\n",
      "Cost for 100k queries: 99.25 $\n",
      "Cost per query:  0.0009925 $ \n",
      "\n",
      "Here is a brief summary of the short story \"Killer in the Willows\":\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"summary\": \"The story follows a woman who, in a moment of fear, shoots and kills an intruder in her home. She then escapes through the window and runs into the nearby willows, trying to evade the other intruder she believes is still in the house. As she hides in the willows, she reflects on the events that led to the killing and her attempt to escape. Eventually, she decides to seek help from her neighbors, the Seymours, but when she arrives at their home, she realizes they have already been informed about the killing and suspect her as the murderer. The story ends with the woman trapped in the Seymours' home, realizing that she has nowhere left to run.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "question = 'KILLER IN THE WILLOWS'\n",
    "num_prompt = 3\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'GPT-4-1106-preview' + END, '\\n')\n",
    "st = time.time()\n",
    "result_gpt = gpt_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_gpt.usage.prompt_tokens)\n",
    "print('Number of output tokens:', result_gpt.usage.completion_tokens, '\\n')\n",
    "print('Cost for 100k queries: ', f'${cost_gpt(100000,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $')\n",
    "print('Cost per query: ', f'${cost_gpt(1,result_gpt.usage.prompt_tokens,result_gpt.usage.completion_tokens)} $','\\n')\n",
    "for l in result_gpt.choices[0].message.content.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Opus' + END, '\\n')\n",
    "st = time.time()\n",
    "result_opus = opus_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_opus.usage.input_tokens)\n",
    "print('Number of output tokens:', result_opus.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_opus(100000,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_opus(1,result_opus.usage.input_tokens,result_opus.usage.output_tokens)} $','\\n')\n",
    "for l in result_opus.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Sonnet' + END, '\\n')\n",
    "st = time.time()\n",
    "result_sonnet = sonnet_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_sonnet.usage.input_tokens)\n",
    "print('Number of output tokens:', result_sonnet.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_sonnet(100000,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_sonnet(1,result_sonnet.usage.input_tokens,result_sonnet.usage.output_tokens)} $','\\n')\n",
    "for l in result_sonnet.content[0].text.split('\\n'):\n",
    "        print(l)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print(BLUE + 'Haiku' + END, '\\n')\n",
    "st = time.time()\n",
    "result_haiku = haiku_description(question, num_prompt)\n",
    "print('Time: ', round(time.time()-st, 2),'seconds','\\n')\n",
    "print('Number of input tokens:', result_haiku.usage.input_tokens)\n",
    "print('Number of output tokens:', result_haiku.usage.output_tokens, '\\n')\n",
    "print('Cost for 100k queries: 'f'{cost_haiku(100000,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $')\n",
    "print('Cost per query: ', f'{cost_haiku(1,result_haiku.usage.input_tokens,result_haiku.usage.output_tokens)} $','\\n')\n",
    "for l in result_haiku.content[0].text.split('\\n'):\n",
    "        print(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
